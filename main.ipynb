{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "224aecd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set MPS fallback to enable operations not supported natively on Apple Silicon\n",
    "import os\n",
    "os.environ['PYTORCH_ENABLE_MPS_FALLBACK'] = '1'\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import bopt\n",
    "import h5py as h5\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2aed0ea7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- device:0 has 1\n",
      "--- device:1 has 1\n",
      "--- device:2 has 3\n",
      "--- device:3 has 1\n",
      "--- device:4 has 1\n",
      "--- device:5 has 1\n",
      "--- device:6 has 0\n",
      "--- device:7 has 0\n",
      "Selected device: cuda:6\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f90e8102d50>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_rate = 50\n",
    "device = bopt.cuda_init()  # Using specific GPU\n",
    "# device='cuda:7'\n",
    "samplerate = 50\n",
    "num_before = 25\n",
    "num_after = 5\n",
    "seed = 2222\n",
    "torch.random.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6845416e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's first load the h5 and see what's inside\n",
    "h5_filepath = '/home/sunnyliu1220/git/latent-gaze/data/charm_50_rec_reduced.h5'\n",
    "charmander_clusters= [ 4, 15, 41, 42, 43, 50, 62, 107, 121, 168, 225, 226, 245, 251, 259, 261,\n",
    "    263, 271, 282, 294, 302, 327, 334, 340, 342, 347, 363, 364, 367, 375, 400,\n",
    "    555\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0651ec02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keys in the reduced h5 file: ['data', 'meta']\n",
      "\n",
      "Data structure:\n",
      "  Series: series_008\n",
      "    Epoch: epoch_001\n",
      "      Group: firing_rates\n",
      "      Group: signals\n",
      "      Group: stimulus\n",
      "  Series: series_009\n",
      "    Epoch: epoch_001\n",
      "      Group: firing_rates\n",
      "      Group: signals\n",
      "      Group: stimulus\n",
      "\n",
      "Metadata structure:\n",
      "  cluster_ids\n",
      "  reconstruction\n",
      "\n",
      "File size: 636.14 MB\n"
     ]
    }
   ],
   "source": [
    "# Let's verify the contents of our newly created H5 file\n",
    "with h5.File(h5_filepath, 'r') as f:\n",
    "    # Print the high-level structure\n",
    "    print(\"Keys in the reduced h5 file:\", list(f.keys()))\n",
    "    \n",
    "    # Check data structure\n",
    "    print(\"\\nData structure:\")\n",
    "    for series_key in f['data'].keys():\n",
    "        print(f\"  Series: {series_key}\")\n",
    "        for epoch_key in f['data'][series_key].keys():\n",
    "            print(f\"    Epoch: {epoch_key}\")\n",
    "            for group_key in f['data'][series_key][epoch_key].keys():\n",
    "                print(f\"      Group: {group_key}\")\n",
    "    \n",
    "    # Check metadata\n",
    "    print(\"\\nMetadata structure:\")\n",
    "    for meta_key in f['meta'].keys():\n",
    "        print(f\"  {meta_key}\")\n",
    "    \n",
    "    # Check file size\n",
    "    import os\n",
    "    print(f\"\\nFile size: {os.path.getsize(h5_filepath) / (1024*1024):.2f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e20c262a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zeroing out blinks in stimulus (at init).\n"
     ]
    }
   ],
   "source": [
    "direction='shifted'\n",
    "# test_series = ['series_008/epoch_001', 'series_009/epoch_001']\n",
    "test_series = ['series_008/epoch_001']\n",
    "test_idxs = [-samplerate * 10, -1]\n",
    "test_all = [0, -1]\n",
    "\n",
    "test_dataset_shifted = bopt.CorticalDataset(h5_filepath,\n",
    "                                    test_series,\n",
    "                                    num_before=num_before,\n",
    "                                    num_after=num_after,\n",
    "                                    start_idx=test_all[0],\n",
    "                                    end_idx=test_all[1],\n",
    "                                    stimulus_key='shifted',\n",
    "                                    grayscale=True,\n",
    "                                    normalize_signals=False,\n",
    "                                    signals=['locomotion', 'azimuth'],\n",
    "                                    which_clusters=charmander_clusters,\n",
    "                                    zero_blinks=True)\n",
    "\n",
    "test_loader_shifted = torch.utils.data.DataLoader(test_dataset_shifted,\n",
    "                                          batch_size=256,\n",
    "                                          shuffle=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0bee3e7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_969151/386723824.py:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model = torch.load(model_path, map_location=device)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CNNComponent(\n",
       "  (layers): ModuleDict(\n",
       "    (conv0): Conv2d(30, 24, kernel_size=(7, 7), stride=(1, 1), padding=valid)\n",
       "    (layernorm0): LayerNorm((24, 62, 96), eps=1e-05, elementwise_affine=False)\n",
       "    (dropout0): Dropout(p=0.1, inplace=False)\n",
       "    (nl0): Softplus(beta=1.0, threshold=20.0)\n",
       "    (conv1): Conv2d(24, 24, kernel_size=(7, 7), stride=(1, 1), padding=valid)\n",
       "    (layernorm1): LayerNorm((24, 56, 90), eps=1e-05, elementwise_affine=False)\n",
       "    (dropout1): Dropout(p=0.1, inplace=False)\n",
       "    (nl1): Softplus(beta=1.0, threshold=20.0)\n",
       "    (conv2): Conv2d(24, 24, kernel_size=(7, 7), stride=(1, 1), padding=valid)\n",
       "    (layernorm2): LayerNorm((24, 50, 84), eps=1e-05, elementwise_affine=False)\n",
       "    (dropout2): Dropout(p=0.1, inplace=False)\n",
       "    (nl2): Softplus(beta=1.0, threshold=20.0)\n",
       "    (conv3): Conv2d(24, 24, kernel_size=(7, 7), stride=(1, 1), padding=valid)\n",
       "    (layernorm3): LayerNorm((24, 44, 78), eps=1e-05, elementwise_affine=False)\n",
       "    (dropout3): Dropout(p=0.1, inplace=False)\n",
       "    (nl3): Softplus(beta=1.0, threshold=20.0)\n",
       "    (conv4): Conv2d(24, 24, kernel_size=(7, 7), stride=(1, 1), padding=valid)\n",
       "    (layernorm4): LayerNorm((24, 38, 72), eps=1e-05, elementwise_affine=False)\n",
       "    (dropout4): Dropout(p=0.1, inplace=False)\n",
       "    (nl4): Softplus(beta=1.0, threshold=20.0)\n",
       "    (conv5): Conv2d(24, 24, kernel_size=(7, 7), stride=(1, 1), padding=valid)\n",
       "    (layernorm5): LayerNorm((24, 32, 66), eps=1e-05, elementwise_affine=False)\n",
       "    (dropout5): Dropout(p=0.1, inplace=False)\n",
       "    (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "    (fc): Linear(in_features=50688, out_features=24, bias=True)\n",
       "    (output): Softplus(beta=1.0, threshold=20.0)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_path = '/home/sunnyliu1220/git/latent-gaze/models/final_model.pt'\n",
    "# Load the model\n",
    "model = torch.load(model_path, map_location=device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29ec09e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_log_lkhd(x, y, z_grid_masked, model, device=device):\n",
    "    \"\"\"\n",
    "    Compute the log likelihood of the model given the input data.\n",
    "    Assume the eye position doens't change during the window.\n",
    "\n",
    "    Parameters:\n",
    "    x (torch.Tensor): Originally shifted stimulus. Shape (T, H, W).\n",
    "    y (torch.Tensor): Ground truth neural activity. Shape (N).\n",
    "    z_grid_masked (torch.Tensor): Masked grid of latent eye position. Shape (M, 2).\n",
    "    model (torch.nn.Module): The trained model.\n",
    "    device (torch.device): The device to run the model on.\n",
    "    \"\"\"\n",
    "    with torch.no_grad():\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        z_grid_masked = z_grid_masked.to(device)\n",
    "        # Let's shift the stimulus first\n",
    "        x_shifted = utils.shift_stimulus(x, z_grid_masked[0], z_grid_masked[1]) # (T, M, H, W)\n",
    "        x_shifted = x_shifted.transpose(0, 1) # (M, T, H, W)\n",
    "        # Now we can pass the shifted stimulus through the model\n",
    "        y_pred = model(x_shifted) # (M, N)\n",
    "        # Compute the log likelihood assuming Gaussian noise\n",
    "        log_likelihood = -0.5 * torch.sum((y_pred - y.unsqueeze(0)) ** 2, dim=1)\n",
    "        return log_likelihood"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
